{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML Challenge\n",
    "\n",
    "In questa sfida, i partecipanti svilupperanno un modello per prevedere i livelli di PM25 sulla base delle misurazioni di umidità e PM10. Questa sfida simula uno scenario reale in cui si vuole stimare il particolato fine (PM25) utilizzando parametri più facilmente misurabili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn pandas scikit-learn torch pennylane qbraid\n",
    "# Use the CRS4 environment for this challenge!\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# read in the data set\n",
    "from client_grader import * \n",
    "grader=Crs4GraderClient()\n",
    "df = pd.read_csv('./particolato.csv',index_col=0, dtype={ \"sensors.humidify\": \"int64\", \"sensors.pm10\":\"float64\", \"sensors.pm25\":\"float64\"}, parse_dates=[\"Time\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay lets try doing some EDA on this \n",
    "\n",
    "df.dropna(inplace=True)\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Basic information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "# Summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.pairplot(df[['sensors.humidity', 'sensors.pm10', 'sensors.pm25']])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[['sensors.humidity', 'sensors.pm10', 'sensors.pm25']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot( df['sensors.pm25'], label='PM2.5')\n",
    "plt.plot( df['sensors.pm10'], label='PM10')\n",
    "plt.title('PM2.5 and PM10 over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Concentration')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Engineering\n",
    "df['hour'] = df.index.hour\n",
    "df['day_of_week'] = df.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df[['sensors.humidity', 'sensors.pm10', 'hour', 'day_of_week']]\n",
    "y = df['sensors.pm25']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default tensor type to float32\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "# Define the quantum device\n",
    "n_features = X_train.shape[1]\n",
    "print(f\"Number of features: {n_features}\")\n",
    "print(f\"Number of qubits: {min(n_features, 10)}\")\n",
    "\n",
    "n_qubits = min(n_features, 10)  # Limit the number of qubits to a maximum of 10\n",
    "\n",
    "# Define the quantum circuit\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_circuit(inputs, weights):\n",
    "    # YOUR CODE HERE\n",
    "    # --------------\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    # --------------\n",
    "    # Return the expectation value of Pauli-Z\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "class HybridModel(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_qubits):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_qubits = n_qubits\n",
    "        self.pre_net = torch.nn.Linear(n_features, n_qubits)\n",
    "        self.q_params = torch.nn.Parameter(torch.randn(3, n_qubits))\n",
    "        self.post_net = torch.nn.Linear(n_qubits, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_net(x)\n",
    "        x = torch.stack([torch.tensor(quantum_circuit(x_i.unsqueeze(0) if x_i.dim() == 0 else x_i, self.q_params), dtype=torch.float32) for x_i in x])\n",
    "        x = self.post_net(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = HybridModel(n_features, n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Ensure input data is float32\n",
    "X_train_tensor = X_train_tensor.float()\n",
    "y_train_tensor = y_train_tensor.float()\n",
    "X_test_tensor = X_test_tensor.float()\n",
    "y_test_tensor = y_test_tensor.float()\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_test_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_tensor)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred.numpy())\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual PM2.5')\n",
    "plt.ylabel('Predicted PM2.5')\n",
    "plt.title('Actual vs Predicted PM2.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=.7, random_state=42)\n",
    "\n",
    "# Scale the validation and test sets\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values).reshape(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred, threshold=0.2):\n",
    "    correct = torch.abs(y_true - y_pred) < threshold\n",
    "    print(correct)\n",
    "    return correct.float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_val_pred = model(X_val_tensor)\n",
    "    val_accuracy = compute_accuracy(y_val_tensor, y_val_pred)\n",
    "    \n",
    "print(f\"Validation Accuracy (threshold=0.2): {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred.numpy())\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred.numpy()))\n",
    "\n",
    "print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor)\n",
    "    test_accuracy = compute_accuracy(y_test_tensor, y_test_pred)\n",
    "    \n",
    "test_mae = mean_absolute_error(y_test, y_test_pred.numpy())\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred.numpy()))\n",
    "\n",
    "print(f\"Test Accuracy (threshold=0.2): {test_accuracy:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_test_pred.numpy(), alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual PM2.5')\n",
    "plt.ylabel('Predicted PM2.5')\n",
    "plt.title('Actual vs Predicted PM2.5 (Test Set)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sottomissione della sfida per ottenere il punteggio\n",
    "\n",
    "Abbiamo integrato il sistema di punteggio nella piattaforma qBraid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the model weights\n",
    "model_path = 'model_weights.pth'\n",
    "# Check if the model weights file exists\n",
    "if os.path.exists(model_path):\n",
    "    # Load the model\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Model weights loaded successfully!\")\n",
    "\n",
    "# Get the full path to the model weights file\n",
    "model_path = pathlib.Path(model_path).resolve()\n",
    "print(str(model_path))\n",
    "\n",
    "grader.check_submission(str(model_path), '13.1')\n",
    "result = grader.submit_exercise(str(model_path), '13.1')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'elaborazione dei risultati potrebbe richiedere del tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dopo qualche minuto, controllate [la classifica in tempo reale](https://account.qbraid.com/hackathons/2024/crs4) per vedere come si classifica il vostro team!\n",
    "\n",
    "🍀 In bocca al lupo! Speriamo che tu ti diverta a cimentarti in questa sfida .🤞 🥳 🎉\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 👉 [La classifica in tempo reale](https://account.qbraid.com/hackathons/2024/crs4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visitate il link qua sopra per vedere che punteggio avete ottenuto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [Default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
